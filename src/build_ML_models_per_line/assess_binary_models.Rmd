---
title: "Assess Classification Models"
author: "Matthew Berginski"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(here)
library(tidymodels)
library(ROCR)
library(patchwork)
library(tictoc)
library(ggtext)
library(gghighlight)

knitr::opts_knit$set(root.dir = here())
```

# Convenience Functions

```{r}
process_full_roc_data <- function(all_results, cell_line, required_data_vals = NA) {
	
	#Some of the hyperparameter settings throw errors on specific data sets
	#resulting in fewer than expected results being returned. This variable makes
	#sure that all the tested hyperparameter config have the expected number of
	#predictions returned.
	if (is.na(required_data_vals)) {
		required_data_vals = max(all_results %>% count(.config) %>% pull(n))
	}
	
	roc_vals = data.frame()
	for (model_id in unique(all_results$.config)) {
		these_results = all_results %>% filter(.config == model_id)
		
		if (dim(these_results)[1] < required_data_vals) {
			next;
		}
		pred <- prediction(these_results$.pred_TRUE,these_results$target_viability_split)
		perf_roc <- performance(pred, measure = "auc")
		prc_roc <- performance(pred, measure = "aucpr")
		
		roc_vals = bind_rows(
			roc_vals,
			data.frame(model_id = model_id,roc = perf_roc@y.values[[1]],prc = prc_roc@y.values[[1]] )
		)
	}
	
	roc_vals = roc_vals %>%
		mutate(roc_rank = dense_rank(desc(roc)),
					 prc_rank = dense_rank(desc(prc))) %>%
		arrange(roc_rank)
}

get_ROC_curve_values <- function(results, cell_line) {
	pred <- prediction(results$.pred_TRUE,results$target_viability_split)
	perf <- performance(pred,measure = "tpr",x.measure = "fpr")
	return(data.frame(fpr = perf@x.values[[1]],
										tpr = perf@y.values[[1]],
										cell_line = cell_line))
}

get_PRC_curve_values <- function(results, cell_line) {
	pred <- prediction(results$.pred_TRUE,results$target_viability_split)
	perf <- performance(pred,measure = "prec",x.measure = "rec")
	return(data.frame(precision = perf@y.values[[1]],
										recall = perf@x.values[[1]],
										cell_line = cell_line))
}
```

# Rand Forest Model Assessment

```{r}
tic()
all_model_results = data.frame()
best_ROC_curves = data.frame()
best_PRC_curves = data.frame()
best_rand_forest_configs = data.frame()

for (rand_model_file in Sys.glob(here('results/per_cell_line_models/rand_forest_CV_results/*'))) {
	cell_line = str_extract(basename(rand_model_file),"ACH-[[:digit:]]*")
	
	all_predictions = read_rds(rand_model_file) %>% 
		collect_predictions()
	
	model_results = process_full_roc_data(all_predictions) %>%
		mutate(depmap_id = cell_line) %>%
		mutate(model = 'rand_forest')
	
	best_rand_forest_configs = best_rand_forest_configs %>%
		bind_rows(all_predictions %>% 
								filter(.config == model_results$model_id[1]) %>% 
								slice(1) %>%
								mutate(depmap_id = cell_line))
	
	best_ROC_curves = best_ROC_curves %>%
		bind_rows(all_predictions %>% 
								filter(.config == model_results$model_id[1]) %>%
								get_ROC_curve_values(cell_line) %>%
								mutate(model = 'rand_forest'))
	
	best_PRC_curves = best_PRC_curves %>%
		bind_rows(all_predictions %>% 
								filter(.config == model_results$model_id[1]) %>%
								get_PRC_curve_values(cell_line) %>%
								mutate(model = 'rand_forest'))
	
	all_model_results = all_model_results %>%
		bind_rows(model_results)
}

write_rds(best_rand_forest_configs,here('results/per_cell_line_models/best_rand_forest_params.rds'))
toc()
```

```{r}
# tic()
# 
# for (rand_model_file in Sys.glob(here('results/xgboost_models//*'))) {
# 	cell_line = str_extract(basename(rand_model_file),"ACH-[[:digit:]]*")
# 	
# 	all_predictions = read_rds(rand_model_file) %>%
# 		collect_predictions()
# 	
# 	model_results = process_full_roc_data(all_predictions) %>%
# 		mutate(depmap_id = cell_line) %>%
# 		mutate(model = 'xgboost')
# 	
# 	best_ROC_curves = best_ROC_curves %>%
# 		bind_rows(all_predictions %>%
# 								filter(.config == model_results$model_id[1]) %>%
# 								get_ROC_curve_values(cell_line) %>%
# 								mutate(model = 'xgboost'))
# 	
# 	best_PRC_curves = best_PRC_curves %>%
# 		bind_rows(all_predictions %>%
# 								filter(.config == model_results$model_id[1]) %>%
# 								get_PRC_curve_values(cell_line) %>%
# 								mutate(model = 'xgboost'))
# 	
# 	all_model_results = all_model_results %>%
# 		bind_rows(model_results)
# }
# 
# toc()
```

```{r}
# model_comparisons = all_model_results %>%
# 	filter(roc_rank == 1) %>%
# 	select(roc, depmap_id, model) %>%
# 	#one of the model set didn't produce a single winner (lots of ties at 0.5), so
# 	#group here and summarize down to a single score
# 	group_by(depmap_id,model) %>%
# 	summarise(roc = mean(roc)) %>%
# 	pivot_wider(names_from = model, values_from = roc) %>%
# 	mutate(rand_xg_diff = rand_forest - xgboost)
```

# Model Assessment/Visualization

```{r}
best_ROC_scores = all_model_results %>% filter(roc_rank == 1)

roc_score_dist = ggplot(best_ROC_scores, aes(x=roc)) + 
	geom_vline(aes(xintercept=0.5), alpha=0.5, linetype = 2) +
	geom_histogram() +
	labs(x="Best AUROC Score", y="Number of Cell Line Models", 
			 title = paste0("Mean ROC: ", signif(mean(best_ROC_scores$roc),3))) +
	BerginskiRMisc::theme_berginski()

prc_score_dist = ggplot(best_ROC_scores, aes(x=prc)) + 
	geom_vline(aes(xintercept=0.5), alpha=0.5, linetype = 2) +
	geom_histogram() +
	labs(x="Best AUPRC Score", y="Number of Cell Line Models",
			 title = paste0("Mean PRC: ", signif(mean(best_ROC_scores$prc),3))) +
	BerginskiRMisc::theme_berginski()

model_score_plots = roc_score_dist + prc_score_dist
ggsave(here('figures/per_cell_line_model/roc_prc_score_dists.png'), width=8,height=4)
```

```{r}
ROC_plots = ggplot(best_ROC_curves, aes(x=fpr, y=tpr, group=cell_line)) + 
	geom_abline(intercept = 0,slope = 1, alpha=0.5,linetype=2) +
	geom_line(alpha=0.05) + 
	# geom_text(mapping=aes(x=1,y=0,label=text),data=ROC_text,color='black',vjust="inward",hjust="inward",size=3.5) +
	# geom_segment(x=0,y=0,xend=1,yend=1) +
	xlim(c(0,1)) + ylim(c(0,1)) +
	labs(x="False Positive Rate",y="True Positive Rate") +
	BerginskiRMisc::theme_berginski()

PRC_plots = ggplot(best_PRC_curves, aes(x=recall, y=precision,group=cell_line)) + 
	geom_abline(intercept = 0.5,slope = 0, alpha=0.5,linetype=2) +
	geom_line(alpha = 0.05) + 
	labs(x="Recall",y="Precision") +
	BerginskiRMisc::theme_berginski()

model_assess_plots = ROC_plots + PRC_plots
dir.create(here('figures/per_cell_line_model'), recursive = T, showWarnings = F)
ggsave(here('figures/per_cell_line_model/roc_prc.png'), width=8,height=4)
BerginskiRMisc::trimImage(here('figures/per_cell_line_model/roc_prc.png'))
```

# Model Highlights

```{r}
sample_info = read_csv(here('data/PRISM/sample_info.csv'))


best_ROC_curves_highlight = best_ROC_curves %>%
	left_join(sample_info %>% select(DepMap_ID,cell_line_name,primary_disease), by=c('cell_line' = 'DepMap_ID'))

best_PRC_curves_highlight = best_PRC_curves %>%
	left_join(sample_info %>% select(DepMap_ID,cell_line_name,primary_disease), by=c('cell_line' = 'DepMap_ID'))

best_model_ROCs = all_model_results %>%
	filter(roc_rank == 1) %>%
	left_join(sample_info %>% select(DepMap_ID,cell_line_name,primary_disease), by=c('depmap_id' = 'DepMap_ID'))

mda_roc_prc_score = best_model_ROCs %>%
	filter(cell_line_name == "MDA-MB-231")

MDA_MB_231_ROC_plot = ggplot(best_ROC_curves_highlight, aes(x=fpr, y=tpr, color=cell_line_name)) +
	geom_abline(intercept = 0,slope = 1, alpha=0.5,linetype=2) +
	geom_line() +
	gghighlight(cell_line_name == "MDA-MB-231",unhighlighted_params = list(alpha=0.05)) +
	geom_text(data = mda_roc_prc_score, aes(x=Inf, y=-Inf, vjust=-0.2,hjust=1,label=signif(roc,3))) +
	# geom_text(mapping=aes(x=1,y=0,label=text),data=ROC_text,color='black',vjust="inward",hjust="inward",size=3.5) +
	# geom_segment(x=0,y=0,xend=1,yend=1) +
	xlim(c(0,1)) + ylim(c(0,1)) +
	labs(x="False Positive Rate",y="True Positive Rate") +
	BerginskiRMisc::theme_berginski()
MDA_MB_231_ROC_plot

MDA_MB_231_PRC_plot = ggplot(best_PRC_curves_highlight, aes(x=recall, y=precision,color=cell_line_name)) + 
	geom_abline(intercept = 0.5,slope = 0, alpha=0.5,linetype=2) +
	geom_line() + 
	gghighlight(cell_line_name == "MDA-MB-231",unhighlighted_params = list(alpha=0.05)) +
	geom_text(data = mda_roc_prc_score, aes(x=Inf, y=-Inf, vjust=-0.2,hjust=1,label=signif(prc,3))) +
	labs(x="Recall",y="Precision") +
	BerginskiRMisc::theme_berginski()
MDA_MB_231_PRC_plot

MDA_ROC_PRC = MDA_MB_231_ROC_plot + MDA_MB_231_PRC_plot
ggsave(here('figures/MDA_ROC_PRC.png'),width=6,height=3)
BerginskiRMisc::trimImage(here('figures/MDA_ROC_PRC.png'))
```

```{r}
disease_type_ROC_plot = ggplot(best_ROC_curves_highlight, aes(x=fpr, y=tpr, group=cell_line_name, color=primary_disease)) +
	geom_abline(intercept = 0,slope = 1, alpha=0.5,linetype=2) +
	geom_line(alpha=0.5) +
	gghighlight(primary_disease %in% unique(primary_disease), 
							unhighlighted_params = list(alpha=0.05)) +
	# gghighlight(primary_disease == "Breast Cancer",unhighlighted_params = list(alpha=0.05)) +
	xlim(c(0,1)) + ylim(c(0,1)) +
	labs(x="False Positive Rate",y="True Positive Rate") +
	BerginskiRMisc::theme_berginski() +
	facet_wrap(~ primary_disease)
ggsave(here('figures/all_disease_ROC_highlight.png'),height=14,width=14)
```

```{r}
disease_type_ROC_plot = ggplot(best_PRC_curves_highlight, aes(x=recall, y=precision,color=cell_line_name)) + 
	geom_abline(intercept = 0.5,slope = 0, alpha=0.5,linetype=2) +
	geom_line(alpha=0.5) +
	gghighlight(primary_disease %in% unique(primary_disease), 
							unhighlighted_params = list(alpha=0.05)) +
	# gghighlight(primary_disease == "Breast Cancer",unhighlighted_params = list(alpha=0.05)) +
	xlim(c(0,1)) + ylim(c(0,1)) +
	labs(x="Recall",y="Precision") +
	BerginskiRMisc::theme_berginski() +
	facet_wrap(~ primary_disease)
ggsave(here('figures/all_disease_PRC_highlight.png'),height=14,width=14)
```