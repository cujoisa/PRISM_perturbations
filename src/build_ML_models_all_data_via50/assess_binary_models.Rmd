---
title: "Assess Classification Models"
author: "Matthew Berginski"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(here)
library(tidymodels)
library(ROCR)
library(patchwork)
library(tictoc)

knitr::opts_knit$set(root.dir = here())
```

# Convenience Functions

```{r}
process_full_roc_data <- function(all_results) {
	
	roc_vals = data.frame()
	for (model_id in unique(all_results$.config)) {
		these_results = all_results %>% filter(.config == model_id)
		
		pred <- prediction(these_results$.pred_TRUE,these_results$target_viability_split)
		perf_roc <- performance(pred, measure = "auc")
		prc_roc <- performance(pred, measure = "aucpr")
		
		roc_vals = bind_rows(
			roc_vals,
			data.frame(model_id = model_id,roc = perf_roc@y.values[[1]],prc = prc_roc@y.values[[1]] )
		)
	}
	
	roc_vals = roc_vals %>%
		mutate(roc_rank = dense_rank(desc(roc)),
					 prc_rank = dense_rank(desc(prc))) %>%
		arrange(roc_rank)
}

get_ROC_curve_values <- function(results) {
	pred <- prediction(results$.pred_TRUE,results$target_viability_split)
	perf <- performance(pred,measure = "tpr",x.measure = "fpr")
	return(data.frame(fpr = perf@x.values[[1]],
										tpr = perf@y.values[[1]]))
}

get_PRC_curve_values <- function(results) {
	pred <- prediction(results$.pred_TRUE,results$target_viability_split)
	perf <- performance(pred,measure = "prec",x.measure = "rec")
	return(data.frame(precision = perf@y.values[[1]],
										recall = perf@x.values[[1]]))
}
```

# Rand Forest Model Assessment

```{r}
tic()

for (feat_count in c(200,500,1000,1500)) {
	model_roc_prc = data.frame()
	
	for (hyper in 1:18) {
		model_files = Sys.glob(here('results/single_model_all_data_via50',sprintf('rand_forest_param_scan_%dfeat',feat_count),sprintf('hyper%03d*.rds', hyper)))
		
		hyper_set_predictions = data.frame()
		for (this_file in model_files) {
			hyper_set_predictions = bind_rows(
				hyper_set_predictions,
				read_rds(this_file) %>% 
					collect_predictions() 
			)
		}
		stopifnot(length(unique(hyper_set_predictions$trees)) == 1)
		stopifnot(length(unique(hyper_set_predictions$mtry)) == 1)
		stopifnot(length(unique(hyper_set_predictions$min_n)) == 1)
		
		model_roc_prc = bind_rows(
			model_roc_prc,
			process_full_roc_data(hyper_set_predictions) %>% 
				mutate(hyper_set = hyper, 
							 trees = unique(hyper_set_predictions$trees),
							 mtry = unique(hyper_set_predictions$mtry),
							 min_n = unique(hyper_set_predictions$min_n))
		)
		if (hyper %% 2 == 0) {
			print(sprintf('Done with %d\n',hyper))
		}
	}
	
	model_roc_prc = model_roc_prc %>%
		mutate(prc_rank = min_rank(desc(prc)),
					 roc_rank = min_rank(desc(roc))) %>%
		arrange(roc_rank)
	print(model_roc_prc)
	
	write_csv(model_roc_prc,here('results/single_model_all_data_via50/',sprintf('hyper_param_results_%dfeat.csv',feat_count)))
}

toc()
```

```{r}
tic()

for (feat_count in c(200,500,1000,1500)) {
	model_roc_prc = data.frame()
	
	for (hyper in 1:1) {
		model_files = Sys.glob(here('results/single_model_all_data_via50',sprintf('rand_forest_param_scan_%dfeat_notune',feat_count),sprintf('hyper%03d*.rds', hyper)))
		
		hyper_set_predictions = data.frame()
		for (this_file in model_files) {
			hyper_set_predictions = bind_rows(
				hyper_set_predictions,
				read_rds(this_file) %>% 
					collect_predictions() 
			)
		}

		model_roc_prc = bind_rows(
			model_roc_prc,
			process_full_roc_data(hyper_set_predictions) %>% 
				mutate(hyper_set = hyper, 
							 trees = unique(hyper_set_predictions$trees),
							 mtry = unique(hyper_set_predictions$mtry),
							 min_n = unique(hyper_set_predictions$min_n))
		)
		if (hyper %% 2 == 0) {
			print(sprintf('Done with %d\n',hyper))
		}
	}
	
	model_roc_prc = model_roc_prc %>%
		mutate(prc_rank = min_rank(desc(prc)),
					 roc_rank = min_rank(desc(roc))) %>%
		arrange(roc_rank)
	print(model_roc_prc)
	
	# write_csv(model_roc_prc,here('results/single_model_all_data_via50/',sprintf('hyper_param_results_%dfeat.csv',feat_count)))
}

toc()
```


```{r}
# best_model_results = model_roc_prc %>% filter(roc_rank == 1)
# 
# model_files = Sys.glob(here('results/single_model_depmap_data_via_50/rand_forest_param_scan/',sprintf('hyper%03d*.rds', best_model_results$hyper_set)))
# 
# best_predictions = data.frame()
# for (this_file in model_files) {
# 	model_results = read_rds(this_file)
# 	
# 	imputed_via = model_results$splits[[1]]$data$imputed_viability[model_results$splits[[1]]$out_id]
# 	
# 	best_predictions = bind_rows(
# 		best_predictions,
# 		model_results %>%
# 			collect_predictions() %>%
# 			mutate(imputed_viability = imputed_via)
# 	)
# }
# 
# best_ROC = get_ROC_curve_values(best_predictions)
# best_PRC = get_PRC_curve_values(best_predictions)
```

# Model Assessment/Visualization

```{r}
# ROC_plots = ggplot(best_ROC, aes(x=fpr, y=tpr)) + 
# 	geom_abline(intercept = 0,slope = 1, alpha=0.5,linetype=2) +
# 	geom_line() + 
# 	# geom_text(mapping=aes(x=1,y=0,label=text),data=ROC_text,color='black',vjust="inward",hjust="inward",size=3.5) +
# 	# geom_segment(x=0,y=0,xend=1,yend=1) +
# 	xlim(c(0,1)) + ylim(c(0,1)) +
# 	labs(x="False Positive Rate",y="True Positive Rate", title = best_model_results$roc) +
# 	BerginskiRMisc::theme_berginski()
# 
# PRC_plots = ggplot(best_PRC, aes(x=recall, y=precision)) + 
# 	geom_abline(intercept = mean(as.logical(best_predictions$target_viability_split)),slope = 0, alpha=0.5,linetype=2) +
# 	geom_line() + 
# 	labs(x="Recall",y="Precision", title = best_model_results$prc) +
# 	BerginskiRMisc::theme_berginski()
# 
# model_assess_plots = ROC_plots + PRC_plots
# dir.create(here('figures/single_model_depmap_data_via_50/'), recursive = T, showWarnings = F)
# ggsave(here('figures/single_model_depmap_data_via_50/roc_prc.png'), width=5,height=2.5)
# BerginskiRMisc::trimImage(here('figures/single_model_depmap_data_via_50/roc_prc.png'))
```
